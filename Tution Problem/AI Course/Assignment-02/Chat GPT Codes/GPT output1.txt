import os
import numpy as np
import tensorflow as tf

# Constants
IMAGE_SIZE = (224, 224)
BATCH_SIZE = 32
NUM_CLASSES = 5  # Adjust according to your dataset
K = 5  # Number of folds

# Load and preprocess data
def load_data(data_dir):
    data = []
    labels = []
    class_names = sorted(os.listdir(data_dir))
    class_to_idx = {class_name: idx for idx, class_name in enumerate(class_names)}

    for class_name in class_names:
        class_dir = os.path.join(data_dir, class_name)
        for img_name in os.listdir(class_dir):
            img_path = os.path.join(class_dir, img_name)
            img = tf.keras.preprocessing.image.load_img(img_path, target_size=IMAGE_SIZE)
            img = tf.keras.preprocessing.image.img_to_array(img) / 255.0
            data.append(img)
            labels.append(class_to_idx[class_name])
    
    data = np.array(data)
    labels = np.array(labels)
    return data, labels, class_names

# One-hot encode labels
def one_hot_encode(labels, num_classes):
    return np.eye(num_classes)[labels]

# Create the model
def create_model(input_shape, num_classes):
    base_model = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)
    base_model.trainable = False

    inputs = tf.keras.Input(shape=input_shape)
    x = base_model(inputs, training=False)
    x = tf.keras.layers.GlobalAveragePooling2D()(x)
    x = tf.keras.layers.Dense(1024, activation='relu')(x)
    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)
    model = tf.keras.Model(inputs, outputs)
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

# Custom K-fold cross-validation function
def k_fold_cross_validation(data, labels, num_classes, k=K):
    num_samples = len(data)
    indices = np.arange(num_samples)
    np.random.shuffle(indices)
    fold_size = num_samples // k
    precision_scores, recall_scores, f1_scores = [], [], []

    for fold in range(k):
        test_indices = indices[fold * fold_size: (fold + 1) * fold_size]
        train_indices = np.concatenate((indices[:fold * fold_size], indices[(fold + 1) * fold_size:]))
        
        X_train, X_test = data[train_indices], data[test_indices]
        y_train, y_test = labels[train_indices], labels[test_indices]
        
        y_train = one_hot_encode(y_train, num_classes)
        y_test = one_hot_encode(y_test, num_classes)

        model = create_model(input_shape=X_train.shape[1:], num_classes=num_classes)
        model.fit(X_train, y_train, epochs=10, batch_size=BATCH_SIZE, validation_data=(X_test, y_test))

        predictions = model.predict(X_test)
        predicted_classes = np.argmax(predictions, axis=1)
        true_classes = np.argmax(y_test, axis=1)

        precision = np.sum((predicted_classes == true_classes) & (true_classes == 1)) / np.sum(predicted_classes == 1)
        recall = np.sum((predicted_classes == true_classes) & (true_classes == 1)) / np.sum(true_classes == 1)
        f1 = 2 * (precision * recall) / (precision + recall)

        precision_scores.append(precision)
        recall_scores.append(recall)
        f1_scores.append(f1)

    print(f'Average Precision: {np.mean(precision_scores)}')
    print(f'Average Recall: {np.mean(recall_scores)}')
    print(f'Average F1 Score: {np.mean(f1_scores)}')

if __name__ == '__main__':
    data_dir = 'path_to_your_flower_dataset'
    data, labels, class_names = load_data(data_dir)
    k_fold_cross_validation(data, labels, num_classes=NUM_CLASSES)
