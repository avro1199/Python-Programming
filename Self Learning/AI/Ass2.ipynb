{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 223\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model, metrics\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 223\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    224\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m load_data()\n\u001b[0;32m    225\u001b[0m     train_eval_test \u001b[38;5;241m=\u001b[39m split_data()\n",
      "Cell \u001b[1;32mIn[2], line 34\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m():\n\u001b[0;32m     30\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m    Load in a model using the tf.keras.applications model and return it.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m    Insert a more detailed description here\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "'''\n",
    "\n",
    "The functions and classes defined in this module will be called by a marker script. \n",
    "You should complete the functions and classes according to their specified interfaces.\n",
    "\n",
    "No partial marks will be awarded for functions that do not meet the specifications\n",
    "of the interfaces.\n",
    "\n",
    "Last modified 2024-05-07 by Anthony Vanderkop.\n",
    "Hopefully without introducing new bugs.\n",
    "'''\n",
    "\n",
    "\n",
    "### LIBRARY IMPORTS HERE ###\n",
    "import os\n",
    "import numpy as np\n",
    "import keras.applications as ka # type: ignore\n",
    "import keras\n",
    "    \n",
    "def my_team():\n",
    "    '''\n",
    "    Return the list of the team members of this assignment submission as a list\n",
    "    of triplet of the form (student_number, first_name, last_name)\n",
    "    \n",
    "    '''\n",
    "    raise NotImplementedError\n",
    "    \n",
    "def load_model():\n",
    "    '''\n",
    "    Load in a model using the tf.keras.applications model and return it.\n",
    "    Insert a more detailed description here\n",
    "    '''\n",
    "    raise NotImplementedError\n",
    "    \n",
    "\n",
    "def load_data(path):\n",
    "    '''\n",
    "    Load in the dataset from its home path. Path should be a string of the path\n",
    "    to the home directory the dataset is found in. Should return a numpy array\n",
    "    with paired images and class labels.\n",
    "    \n",
    "    Insert a more detailed description here.\n",
    "    '''\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    \n",
    "def split_data(X, Y, train_fraction, randomize=False, eval_set=True):\n",
    "    \"\"\"\n",
    "    Split the data into training and testing sets. If eval_set is True, also create\n",
    "    an evaluation dataset. There should be two outputs if eval_set there should\n",
    "    be three outputs (train, test, eval), otherwise two outputs (train, test).\n",
    "    \n",
    "    To see what type train, test, and eval should be, refer to the inputs of \n",
    "    transfer_learning().\n",
    "    \n",
    "    Insert a more detailed description here.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    \n",
    "\n",
    "def confusion_matrix(predictions, ground_truth, plot=False, all_classes=None):\n",
    "    '''\n",
    "    Given a set of classifier predictions and the ground truth, calculate and\n",
    "    return the confusion matrix of the classifier's performance.\n",
    "\n",
    "    Inputs:\n",
    "        - predictions: np.ndarray of length n where n is the number of data\n",
    "                       points in the dataset being classified and each value\n",
    "                       is the class predicted by the classifier\n",
    "        - ground_truth: np.ndarray of length n where each value is the correct\n",
    "                        value of the class predicted by the classifier\n",
    "        - plot: boolean. If true, create a plot of the confusion matrix with\n",
    "                either matplotlib or with sklearn.\n",
    "        - classes: a set of all unique classes that are expected in the dataset.\n",
    "                   If None is provided we assume all relevant classes are in \n",
    "                   the ground_truth instead.\n",
    "    Outputs:\n",
    "        - cm: type np.ndarray of shape (c,c) where c is the number of unique  \n",
    "              classes in the ground_truth\n",
    "              \n",
    "              Each row corresponds to a unique class in the ground truth and\n",
    "              each column to a prediction of a unique class by a classifier\n",
    "    '''\n",
    "    \n",
    "    raise NotImplementedError\n",
    "    return cm\n",
    "    \n",
    "\n",
    "def precision(predictions, ground_truth):\n",
    "    '''\n",
    "    Similar to the confusion matrix, now calculate the classifier's precision\n",
    "    \n",
    "    Inputs: see confusion_matrix above\n",
    "    Outputs:\n",
    "        - precision: type np.ndarray of length c,\n",
    "                     values are the precision for each class\n",
    "    '''\n",
    "    raise NotImplementedError\n",
    "    return precision\n",
    "\n",
    "def recall(predictions, ground_truth):\n",
    "    '''\n",
    "    Similar to the confusion matrix, now calculate the classifier's recall\n",
    "    \n",
    "    Inputs: see confusion_matrix above\n",
    "    Outputs:\n",
    "        - recall: type np.ndarray of length c,\n",
    "                     values are the recall for each class\n",
    "    '''\n",
    "    raise NotImplementedError\n",
    "    return recall\n",
    "\n",
    "def f1(predictions, ground_truth):\n",
    "    '''\n",
    "    Similar to the confusion matrix, now calculate the classifier's f1 score\n",
    "    Inputs:\n",
    "        - see confusion_matrix above for predictions, ground_truth\n",
    "    Outputs:\n",
    "        - f1: type nd.ndarry of length c where c is the number of classes\n",
    "    '''\n",
    "    \n",
    "    raise NotImplementedError\n",
    "    return f1\n",
    "\n",
    "def k_fold_validation(features, ground_truth, classifier, k=2):\n",
    "    '''\n",
    "    Inputs:\n",
    "        - features: np.ndarray of features in the dataset\n",
    "        - ground_truth: np.ndarray of class values associated with the features\n",
    "        - fit_func: f\n",
    "        - classifier: class object with both fit() and predict() methods which\n",
    "        can be applied to subsets of the features and ground_truth inputs.\n",
    "        - predict_func: function, calling predict_func(features) should return\n",
    "        a numpy array of class predictions which can in turn be input to the \n",
    "        functions in this script to calculate performance metrics.\n",
    "        - k: int, number of sub-sets to partition the data into. default is k=2\n",
    "    Outputs:\n",
    "        - avg_metrics: np.ndarray of shape (3, c) where c is the number of classes.\n",
    "        The first row is the average precision for each class over the k\n",
    "        validation steps. Second row is recall and third row is f1 score.\n",
    "        - sigma_metrics: np.ndarray, each value is the standard deviation of \n",
    "        the performance metrics [precision, recall, f1_score]\n",
    "    '''\n",
    "    \n",
    "    #split data\n",
    "    ### YOUR CODE HERE ###\n",
    "    \n",
    "    #go through each partition and use it as a test set.\n",
    "    for partition_no in range(k):\n",
    "        #determine test and train sets\n",
    "        ### YOUR CODE HERE###\n",
    "        \n",
    "        #fit model to training data and perform predictions on the test set\n",
    "        classifier.fit(train_features, train_classes)\n",
    "        predictions = classifier.predict(test_features)\n",
    "        \n",
    "        #calculate performance metrics\n",
    "        ### YOUR CODE HERE###\n",
    "    \n",
    "    #perform statistical analyses on metrics\n",
    "    ### YOUR CODE HERE###\n",
    "    \n",
    "    raise NotImplementedError\n",
    "    return avg_metrics, sigma_metrics\n",
    "\n",
    "\n",
    "##################### MAIN ASSIGNMENT CODE FROM HERE ######################\n",
    "\n",
    "def transfer_learning(train_set, eval_set, test_set, model, parameters):\n",
    "    '''\n",
    "    Implement and perform standard transfer learning here.\n",
    "\n",
    "    Inputs:\n",
    "        - train_set: list or tuple of the training images and labels in the\n",
    "            form (images, labels) for training the classifier\n",
    "        - eval_set: list or tuple of the images and labels used in evaluating\n",
    "            the model during training, in the form (images, labels)\n",
    "        - test_set: list or tuple of the training images and labels in the\n",
    "            form (images, labels) for testing the classifier after training\n",
    "        - model: an instance of tf.keras.applications.MobileNetV2\n",
    "        - parameters: list or tuple of parameters to use during training:\n",
    "            (learning_rate, momentum, nesterov)\n",
    "\n",
    "\n",
    "    Outputs:\n",
    "        - model : an instance of tf.keras.applications.MobileNetV2\n",
    "        - metrics : list of classwise recall, precision, and f1 scores of the \n",
    "            model on the test_set (list of np.ndarray)\n",
    "\n",
    "    '''\n",
    "    raise NotImplementedError\n",
    "    return model, metrics\n",
    "    \n",
    "def accelerated_learning(train_set, eval_set, test_set, model, parameters):\n",
    "    '''\n",
    "    Implement and perform accelerated transfer learning here.\n",
    "\n",
    "    Inputs:\n",
    "        - train_set: list or tuple of the training images and labels in the\n",
    "            form (images, labels) for training the classifier\n",
    "        - eval_set: list or tuple of the images and labels used in evaluating\n",
    "            the model during training, in the form (images, labels)\n",
    "        - test_set: list or tuple of the training images and labels in the\n",
    "            form (images, labels) for testing the classifier after training\n",
    "        - model: an instance of tf.keras.applications.MobileNetV2\n",
    "        - parameters: list or tuple of parameters to use during training:\n",
    "            (learning_rate, momentum, nesterov)\n",
    "\n",
    "\n",
    "    Outputs:\n",
    "        - model : an instance of tf.keras.applications.MobileNetV2\n",
    "        - metrics : list of classwise recall, precision, and f1 scores of the \n",
    "            model on the test_set (list of np.ndarray)\n",
    "\n",
    "    '''\n",
    "    raise NotImplementedError\n",
    "    return model, metrics\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    model = load_model()\n",
    "    dataset = load_data()\n",
    "    train_eval_test = split_data()\n",
    "    \n",
    "    model, metrics = transfer_learning()\n",
    "    \n",
    "    model, metrics = accelerated_learning()\n",
    "    \n",
    "    \n",
    "#########################  CODE GRAVEYARD  #############################\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
